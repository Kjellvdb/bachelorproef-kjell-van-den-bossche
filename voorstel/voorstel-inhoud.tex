\paragraph{Opmerking}

Dit voorstel is gebaseerd op het onderzoeksvoorstel dat werd geschreven in het kader van het vak Research Methods dat ik vorig academiejaar heb uitgewerkt met medestudent Alvaro Van Damme als mede-auteur.

\section{Inleiding}
\label{sec:inleiding}

In de hedendaagse wereld spelen mediabedrijven een cruciale rol in het bieden van informatie. Het is van groot belang dat deze informatie op een objectieve wijze wordt gedeeld, maar de realiteit blijkt niet aan onze verwachtingen te voldoen. Het onpartijdigheidsrapport van de Vlaamse Regulator voor de Media toont aan dat VTM Nieuws, onderdeel van DPG Media, in haar berichtgeving bepaalde politieke partijen meer spreektijd geeft dan andere \autocite{VanAelst2024}. Tegelijkertijd heeft Het Laatste Nieuws, ook onderdeel van DPG Media, volgens dagelijkse rapporten gepubliceerd door het \textcite{CIM2025} al jaren het grootste bereik onder de Vlaamse nieuwswebsites.

Wanneer nieuws niet op neutrale wijze wordt weergegeven, kan dit bijdragen aan een afnemend vertrouwen in de traditionele media \autocite{Hanjia2024}. Bovendien wordt nieuws sneller aangenomen als waarheid wanneer dit hun persoonlijke overtuigingen bevestigt \autocite{Schwalbe2024}. Deze vaststellingen tonen aan dat er nood is aan onderzoek naar automatische detectiesystemen voor journalistieke bias.

Dit onderzoek richt zich op het ontwikkelen van een browserextensie die nieuwsartikelen van Het Laatste Nieuws (HLN) automatisch analyseert en classificeert op basis van hun partijdigheid. Deze extensie is gericht op lezers van HLN die twijfelen aan de neutraliteit van de berichtgeving en die zich bewust willen worden van de mogelijke vooringenomenheid in hun dagelijkse nieuwsconsumptie.

De centrale onderzoeksvraag luidt: Hoe kan een browserextensie ontwikkeld worden die artikelen van Het Laatste Nieuws automatisch classificeert op basis van hun partijdigheid, met minimale impact op de gebruikservaring? Om deze hoofdonderzoeksvraag te beantwoorden, zijn volgende deelvragen geformuleerd:

\begin{itemize}
    \item Welke vormen van journalistieke bias komen voor in nieuwsartikelen?
    \item Welke linguïstische kenmerken duiden op partijdigheid?
    \item Welke bestaande methoden kunnen toegepast worden om bias in teksten te detecteren?
    \item Op welke wijze kan de semantische betekenis van woorden behouden tijdens het classificeren?
\end{itemize}

Het doel van dit onderzoek is het ontwerpen van een Proof-of-Concept (PoC) die automatische detectie en classificatie van journalistieke partijdigheid in nieuwsartikelen realiseert en implementeert in een gebruiksvriendelijke browserextensie.

De Proof-of-Concept classificeert elk artikel als \textit{neutraal} of \textit{niet-neutraal}, gecombineerd met een \textit{confidence score} die de zekerheid van het classificatiemodel weergeeft. Indien een artikel als \textit{niet-neutraal} wordt geclassificeerd, worden zinnen aangeduid die volgens het classificatiemodel het meest hebben bijgedragen aan de classificatie.

De prestaties van de PoC worden geëvalueerd aan de hand van standaard classificatiemetrics, namelijk precision, recall en F1-score, berekend op een testset. Daarnaast wordt een benchmark uitgevoerd waarbij de resultaten worden vergeleken met bestaande oplossingen voor mediabiasdetectie, zoals \textit{Ground News} en \textit{Media Bias}.

\section{Literatuurstudie}
\label{sec:literatuurstudie}

\subsection{Vormen van journalistieke vooringenomenheid}

Inzicht in de verschillende vormen van journalistieke bias en hoe deze geïdentificeerd kunnen worden, is een essentieel onderdeel van dit onderzoek.

\subsubsection{Ideology bias en spin bias}

Volgens \textcite{Mullainathan2002} kan journalistieke bias onderverdeeld worden in twee categorieën: \textit{ideology bias} en \textit{spin bias}. 

Bij \textit{ideology bias} wordt de inhoud van een artikel in bepaalde ideologische richtingen gestuurd. In veel gevallen reflecteert deze vorm van partijdigheid de voorkeuren van het mediabedrijf en haar doelgroep \autocite{Mullainathan2002}. Het sturen van nieuwsartikelen in bepaalde politieke richtingen is ook waargenomen bij VTM Nieuws, in het onpartijdigheidsrapport gepubliceerd door de Vlaamse Regulator voor de Media \autocite{VanAelst2024}.

In het geval van \textit{spin bias} wordt informatie in een artikel gemanipuleerd met als doel het artikel opvallender of sensationeler te maken. Door concurrentie tussen nieuwsorganisaties worden journalisten aangemoedigd om opvallende artikelen te schrijven, wat bereikt kan worden door feiten te verdraaien of te overdrijven \autocite{Alsem2008}. Er is momenteel nog geen onderzoek uitgevoerd naar het aandeel van \textit{spin bias} in artikelen gepubliceerd door Het Laatste Nieuws.

\subsubsection{Gatekeeping, coverage bias en state\-ment bias}

\textcite{SaezTrumper2013} verdeelt journalistie\-ke bias in drie andere categorieën: \textit{gatekeeping}, \textit{coverage bias} en \textit{statement bias}.

\textit{Gatekeeping}, ook wel \textit{selection bias} genoemd, wordt door \textcite{CALD2025} gedefinieerd als het bepalen van wie bepaalde informatie, macht of kansen krijgt. Hierbij kiest de auteur een specifieke selectie van informatie voor het artikel en laat andere informatie achterwege. Dit komt vaak voor in kranten, waar auteurs gedwongen worden om een selectie van informatie te maken vanwege de beperkte ruimte \autocite{SaezTrumper2013}.

Bij \textit{coverage bias} wordt meer aandacht toegekend aan bepaalde onderdelen in vergelijking met andere \autocite{DAlessio2006}. Deze extra aandacht kan zich uiten in meer zendtijd op televisie, meer spreektijd op de radio of meer tekst in artikelen.

\textit{Statement bias}, ook wel \textit{presentation bias} genoemd, verwijst naar het gunstiger omschrijven van bepaalde onderdelen ten koste van andere onderdelen \autocite{SaezTrumper2013}. Een mediabericht dat evenveel uitspraken bevat die in de ene richting voordelig zijn als uitspraken die in de tegenovergestelde richting voordelig zijn, kan als neutraal worden beschouwd \autocite{DAlessio2006}.

Voor deze vormen van bias is nog geen onderzoek uitgevoerd naar het aandeel ervan in artikelen van HLN. Het kan echter worden aangenomen dat deze ook aanwezig zijn in artikelen van Het Laatste Nieuws. Deze aanname wordt ondersteund door twee bevindingen:

\begin{itemize}
    \item Volgens \textcite{RodrigoGines2024} wordt media bias steeds meer zichtbaar door de verspreiding van sociale media.
    \item Uit een steekproef van \textcite{Neveneffecten2011} blijkt dat bronnen in krantenartikelen onvoldoende of niet worden gecontroleerd.
\end{itemize}

\subsection{Methoden om bias te detecteren}

Om artikelen op basis van partijdigheid te classificeren, is het belangrijk om bias in een artikel te kunnen detecteren. Dit kan bereikt worden met technieken uit het domein van \textit{Natural Language Processing} (NLP).

Een van de methoden om artikelen te classificeren op basis van partijdigheid is \textit{supervised learning}, waarbij modellen getraind worden op gelabelde data. Vaak wordt gebruik gemaakt van neurale tekstclassificatoren zoals \textit{Bidirectional Encoder Representations from Transformers} (BERT). BERT is een complexe architectuur die contextuele representaties van teksten kan genereren en heeft zich al bewezen als een succesvolle methode voor NLP-taken \autocite{Baly2020}. In het onderzoek van \textcite{Baly2020} werd een biasclassificatiemodel op basis van BERT ontwikkeld. Het model werd getest op artikelen uit kranten die niet in de trainingsset waren opgenomen, om te voorkomen dat de nieuwsbron herkend zou worden en de classificatie zou beïnvloeden. In dit onderzoek zal hier geen rekening mee gehouden worden, aangezien het beperkt is tot één enkele nieuwsbron.

Een andere methode die gebruikt kan worden is \textit{unsupervised learning}, waarbij de dataset niet gelabeld is. Hierbij wordt vaak gebruik gemaakt van vectorisatiemethoden in combinatie met clusteringalgoritmen \autocite{UmarNadeem2022}. Uit een onderzoek van \textcite{UmarNadeem2022} werd geconcludeerd dat deze methode niet effectief is voor het vinden van tekstpatronen. Aangezien deze patronen essentieel zijn voor het detecteren van bias, wordt deze methode als niet effectief beschouwd.

Een derde methode die relevant zou kunnen zijn binnen ons onderzoek is \textit{sentimentanalyse}. Deze techniek richt zich op het identificeren van toon in teksten en kan beoordelen of deze positief, negatief of neutraal is \autocite{Cui2025}. Hoewel deze methode mogelijk niet voldoende is om alle vormen van bias te detecteren, kan het wel in combinatie met een \textit{supervised learning} techniek zoals BERT gebruikt worden om betere resultaten te bereiken.

\subsection{Methodes om tekst te extraheren uit een webpagina}

Voor de ontwikkeling van de browserextensie is het noodzakelijk om de tekst van geopende nieuwsartikelen op de HLN-website te kunnen extraheren. Een veelgebruikte methode hiervoor is het doorlopen van de \textit{Document Object Model} (DOM)-structuur van de webpagina \autocite{GCD2012}. Het DOM vormt een hiërarchische representatie van alle elementen op een webpagina en maakt het mogelijk om deze elementen dynamisch te lezen en te wijzigen. Moderne websites gedragen zich doorgaans consistent binnen verschillende browsers, waardoor het element dat de hoofdinhoud bevat meestal kan worden geïdentificeerd als het element met het grootste tekstvolume op een vergelijkbare diepte in de DOM-structuur \autocite{Aleksandersen2018}.

Hoewel er alternatieve methodes bestaan om tekstextractie te bereiken, wordt dit onderzoek beperkt tot het gebruik van het DOM. De keuze wordt gemotiveerd door het feit dat dit een goed ondersteunde methode is binnen de meest gebruikte browsers.

\subsection{Methodes om semantische betekenis te behouden}

Het behoud van semantische betekenis van woorden is cruciaal binnen dit onderzoek. Een veelgebruikte methode hiervoor is het gebruik van woordembeddings, waarbij woorden worden omgezet in vectorrepresentaties. Volgens \textcite{Akbik2018} kan binnen deze benadering onderscheid worden gemaakt tussen klassieke en contextuele woordembeddings.

Klassieke woordembeddings koppelen ieder woord aan één vaste vector, onafhankelijk van de context waarin het voorkomt. Een bekende techniek binnen deze categorie is \textit{Global Vectors} (GloVe), dat globale corpusstatistieken gebruikt in combinatie met \textit{unsupervised learning} om woorden in een vectorruimte te representeren \autocite{Pennington2014}. Deze modellen kunnen semantische relaties vastleggen, maar houden geen rekening met contextuele betekenissen van individuele woorden.

Om ook contextuele informatie te behouden binnen een vectorrepresentatie, kunnen contextuele woordembeddings worden gebruikt. Deze embeddings genereren representaties die afhankelijk zijn van de context waarin een woord voorkomt binnen een zin \autocite{Akbik2018}. Een belangrijke techniek binnen deze categorie is het gebruik van transformer-gebaseerde representaties zoals BERT \autocite{Khodake2020}, die contextuele informatie kunnen vasthouden in een vectorrepresentatie.

Een andere relevante techniek is het gebruik van \textit{Embeddings from Language Models} (ELMo), waarbij vectorrepresentaties van woorden worden afgeleid uit een bidirectioneel \textit{Long Short-Term Memory}-taalmodel \autocite{Peters2018}. ELMo combineert informatie uit alle interne lagen van het taalmodel tot een gewogen vectorrepresentatie voor elk woord, waardoor zowel semantische als contextuele betekenissen van woorden kunnen worden vastgelegd.

Er bestaan nog andere methoden om semantische betekenis van woorden te behouden, maar deze worden niet opgenomen in deze literatuurstudie.

\subsection{Samenstellen van een dataset}

Het is niet mogelijk om een grootschalige, gelabelde dataset van nieuwsartikelen van Het Laatste Nieuws te verkrijgen. Handmatige labeling van een dergelijke dataset is bovendien niet haalbaar, vanwege tijdsbeperkingen en de complexiteit en tijdsintensiviteit van het beoordelen van bias in nieuwsartikelen. Om deze beperking te omzeilen, wordt gekozen voor een trainingsstrategie waarbij het model wordt getraind op drie verschillende datasets, die elk een specifieke rol vervullen binnen het classificatieproces.

\begin{enumerate}
    \item \textit{Metadata-dataset}: Deze dataset bevat aanvullende informatie over nieuwsartikelen, zoals publiekelijk beschikbare gegevens over de auteur(s). Deze informatie wordt verzameld via webscraping van de HLN-website. De metadata kan worden gebruikt om patronen in partijdigheid over meerdere publicaties van een auteur te identificeren, die gebruikt worden als aanvullende context bij de biasclassificatie.
    \item \textit{Sentence‑level dataset}: Op zinsniveau gelabelde datasets, zoals de \textit{FactNews}-dataset \autocite{Vargas2024}, voorgesteld in het onderzoek van \textcite{Vargas2023}, worden gebruikt om een model te trainen dat indicaties van bias binnen individuele zinnen kan detecteren. Deze datasets zijn oorspronkelijk in andere talen beschikbaar, waardoor ze vooraf worden vertaald naar het Nederlands. De datasets maken het mogelijk om zinnen die het sterkst bijdragen aan de uiteindelijke biasclassificatie van een artikel te identificeren.
    \item \textit{Document‑level dataset}: Voor training op documentniveau wordt een fijnschalige gelabelde dataset van HLN-artikelen gebruikt, waarbij biaslabels worden afgeleid uit externe media bias checkers, zoals \textit{Media Bias} en \textit{Ground News}. Als alternatief kan gebruik worden gemaakt van bestaande document-level datasets, zoals de \textit{NewsMediaBias-Plus} dataset \autocite{Raza2024}, waarbij artikelen vooraf worden vertaald naar het Nederlands. Deze dataset wordt gebruikt voor de globale biasclassificatie van een nieuwsartikel.
\end{enumerate}

Het uiteindelijke model bestaat uit drie afzonderlijke pipelines die elk worden getraind op hun respectievelijke dataset. De outputs van de meta\-data- en sentence-level pipelines geven invloed tijdens de document-level pipeline. Door deze aanpak kan een model ontwikkeld worden zonder dat een grootschalige, handmatig gelabelde dataset van HLN-artikelen vereist is.

\section{Methodologie}
\label{sec:methodologie}

Dit onderzoek volgt een Agile werkwijze waarbij literatuurstudie, ontwerp, evaluatie en rapportering elkaar afwisselen. De methodologie is gericht op het systematisch verzamelen van kennis, het ontwikkelen van een Proof-of-Concept, het uitvoeren van experimenten en het verwerken van de resultaten. De volledige tijdsplanning wordt weergegeven in Figuur \ref{fig:gantt}.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{img/gantt-chart}
    \caption{\label{fig:gantt}Gantt-diagram met de verschillende fasen en milestones van het onderzoek.}
\end{figure*}

\subsection{Literatuurstudie}

Het onderzoek start met een gerichte literatuurstudie die de basis vormt voor de ontwikkeling van de PoC, het opzetten van de experimenten en het verwerken van de resultaten. De literatuurstudie wordt doorheen het onderzoek iteratief aangevuld, zodat nieuwe inzichten onmiddellijk kunnen worden toegepast. De iteratieve eigenschap van dit onderzoek wordt weergegeven in Figuur \ref{fig:flow}.

\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{img/flowchart}
    \caption{\label{fig:flow}Flowchart met de verschillende fasen van het onderzoek.}
\end{figure*}

\subsection{Bachelorproefvoorstel}

Parallel aan de literatuurstudie wordt het bachelorproefvoorstel opgesteld. Een eerste versie wordt ingediend voor feedback, waarna een tweede versie uitgewerkt wordt op basis van de aanbevelingen van de promotor. Het voorstel vormt het startpunt van het onderzoek.

\subsection{Proof-of-Concept}

Op basis van de literatuurstudie wordt een PoC ontwikkeld. Deze omvat de dataverwerkingspipeline voor het verwerken van artikelen, een classificatiemodel voor het detecteren van journalistieke bias en een browserextensie die de resultaten van het model visualiseert. De implementatie verloopt parallel aan de literatuurstudie, zodat nieuwe inzichten kunnen worden toegepast in de uitwerking van het ontwerp.

\subsection{Experimenten}

Wanneer de PoC voldoende stabiel is, kunnen experimenten worden opgezet. Deze omvatten functionele testen, prestatietesten en vergelijkingen met bestaande oplossingen. Alle experimenten worden uitgevoerd in een reproduceerbare, repliceerbare en herbruikbare omgeving.

\subsection{Resultaten}

De resultaten van de experimenten worden systematisch geanalyseerd en verwerkt. De analyses vormen de basis voor het beantwoorden van de onderzoeksvragen. Deze bevindingen worden samengevat in grafieken, tabellen en figuren, die in de bachelorproef worden opgenomen.

\subsection{Bachelorproef}

Gedurende het onderzoek wordt de bachelorproef systematisch aangevuld met nieuwe inzichten, resultaten en conclusies.

\section{Verwachte resultaten}
\label{sec:verwachte-resultaten}

Het verwachte resultaat van dit onderzoek is een functionele Proof-of-Concept die nieuwsartikelen van Het Laatste Nieuws kan analyseren en classificeren op basis van journalistieke bias. De belangrijkste componenten van de PoC zijn:

\begin{itemize}
    \item Een dataverwerkingspipeline die nieuwsartikelen automatisch kan extraheren uit webpagina's en deze op een consistente en stabiele manier kan preprocessen.
    \item Een getraind classificatiemodel dat journalistieke bias in tekst kan detecteren met een hoge nauwkeurigheid, waarbij een minima\-le F1-score van 0,80 op een testset wordt verwacht.
    \item Een gebruikersinterface die de classificatieresultaten op een duidelijke en interpreteerbare wijze visualiseert, zonder merkbare vertragingen bij het laden van nieuwsartikelen.
\end{itemize}

Het doel is dat de extensie betrouwbare resultaten oplevert, zodat gebruikers zich bewust kunnen worden van de mogelijke journalistieke vooringenomenheid in nieuwsartikelen en hun nieuws kritisch kunnen consumeren.

\section{Conclusie}
\label{sec:conclusie}

Uit dit onderzoek zal blijken in welke mate een automatische biasdetectie-extensie realiseerbaar en bruikbaar is voor nieuwsartikelen van Het Laatste Nieuws. Het onderzoek biedt inzicht in de effectiviteit van NLP-methoden voor het detecteren van journalistieke bias binnen één specifieke nieuwsbron.

Afwijkingen tussen de verwachte en daadwerkelijke resultaten zullen belangrijke inzichten geven over de betrouwbaarheid van automatische biasdetectiesystemen. Daarnaast zal het onderzoek aantonen hoe een dergelijk systeem kan bijdragen aan kritisch mediagebruik.